{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ-hdEr2l5yD"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-GDnhTdmq-e",
        "outputId": "535a56fc-ceee-44a7-d3e5-c8e1388599fa"
      },
      "source": [
        "cd first"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/first\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpIchvdTmJue",
        "outputId": "3309a8c8-a6f0-46b7-f49a-73223a627692"
      },
      "source": [
        "# loading training set features\n",
        "f = open(\"Datasets/train_set_features.pkl\", \"rb\")\n",
        "train_set_features2 = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "# reducing feature vector length \n",
        "features_STDs = np.std(a=train_set_features2, axis=0)\n",
        "train_set_features = train_set_features2[:, features_STDs > 52.3]\n",
        "\n",
        "# changing the range of data between 0 and 1\n",
        "train_set_features = np.divide(train_set_features, train_set_features.max())\n",
        "\n",
        "# loading training set labels\n",
        "f = open(\"Datasets/train_set_labels.pkl\", \"rb\")\n",
        "train_set_labels = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "# ------------\n",
        "# loading test set features\n",
        "f = open(\"Datasets/test_set_features.pkl\", \"rb\")\n",
        "test_set_features2 = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "# reducing feature vector length \n",
        "features_STDs = np.std(a=test_set_features2, axis=0)\n",
        "test_set_features = test_set_features2[:, features_STDs > 48]\n",
        "\n",
        "# changing the range of data between 0 and 1\n",
        "test_set_features = np.divide(test_set_features, test_set_features.max())\n",
        "\n",
        "# loading test set labels\n",
        "f = open(\"Datasets/test_set_labels.pkl\", \"rb\")\n",
        "test_set_labels = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "# ------------\n",
        "# preparing our training and test sets - joining datasets and lables\n",
        "train_set = []\n",
        "test_set = []\n",
        "\n",
        "for i in range(len(train_set_features)):\n",
        "    label = np.array([0,0,0,0])\n",
        "    label[int(train_set_labels[i])] = 1\n",
        "    label = label.reshape(4,1)\n",
        "    train_set.append((train_set_features[i].reshape(102,1), label))\n",
        "    \n",
        "\n",
        "for i in range(len(test_set_features)):\n",
        "    label = np.array([0,0,0,0])\n",
        "    label[int(test_set_labels[i])] = 1\n",
        "    label = label.reshape(4,1)\n",
        "    test_set.append((test_set_features[i].reshape(102,1), label))\n",
        "\n",
        "# shuffle\n",
        "random.shuffle(train_set)\n",
        "random.shuffle(test_set)\n",
        "\n",
        "# print size\n",
        "print(len(train_set)) #1962\n",
        "print(len(test_set)) #662\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1962\n",
            "662\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfUzwPEjAcLP",
        "outputId": "301c7d9f-f89e-419b-c77d-5810d24ad5d6"
      },
      "source": [
        "minimize_train_set=train_set[:200]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKUu4eermp2s"
      },
      "source": [
        "def sigmoid(x):\n",
        "    ans=1/(1+np.exp(-x))\n",
        "    return ans\n",
        "def result(x,w,b):\n",
        "    return np.dot(w,x)+b\n",
        "\n",
        "np.random.seed(1)\n",
        "n_x=102\n",
        "n_h_1=150\n",
        "n_h_2=60\n",
        "n_y=4\n",
        "#intialize the layers here\n",
        "W1 = np.random.randn(n_h_1,n_x) * 0.01\n",
        "b1 = np.zeros((n_h_1,1))\n",
        "W2 = np.random.randn(n_h_2,n_h_1) * 0.01\n",
        "b2 = np.zeros((n_h_2,1))\n",
        "W3 = np.random.randn(n_y,n_h_2) * 0.01\n",
        "b3 = np.zeros((n_y,1))\n",
        "out=[]\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOKWm_4wcZdF",
        "outputId": "81dd0be4-4282-4287-b497-b8d81a4bee29"
      },
      "source": [
        "for i in range(len(minimize_train_set)):\n",
        "  reshape_train=minimize_train_set[i][0]\n",
        "  reshape_train_lables=minimize_train_set[i][1]\n",
        "  Z1=result(reshape_train,W1,b1)\n",
        "  S1=sigmoid(Z1)\n",
        "  Z2=result(S1,W2,b2)\n",
        "  S2=sigmoid(Z2)\n",
        "  Z3=result(S2,W3,b3)\n",
        "  S3=sigmoid(Z3)\n",
        "  out.append(S3)\n",
        "  cost=0\n",
        "    for index in range(len(S3)):\n",
        "      cost+=pow((S3[index][0]-reshape_train_lables[index][0]),2)\n",
        "      \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.49499065865469766\n",
            "sala\n",
            "0\n",
            "salam0.2450157521554114\n",
            "0.49546131656916353\n",
            "sala\n",
            "0\n",
            "salam0.49049766837186026\n",
            "0.480985099310034\n",
            "sala\n",
            "0\n",
            "salam0.7218443341301436\n",
            "0.49013450227879735\n",
            "sala\n",
            "1\n",
            "salam0.9818071598966334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZknxAED7jQeV"
      },
      "source": [
        "index=[]  \n",
        "for i in out:\n",
        "  k=i.tolist()\n",
        "  max1=0\n",
        "  for count in k:\n",
        "    if(count[0]>max1):\n",
        "      max1=count[0]\n",
        "  for j in range(len(k)):\n",
        "     if(k[j][0]==max1):\n",
        "       index.append(j)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiF5vlDrtbdy"
      },
      "source": [
        "11#|"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}